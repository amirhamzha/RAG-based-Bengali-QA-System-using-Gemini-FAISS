
# ðŸ“š Multilingual Retrieval-Augmented Generation (RAG) System


A Retrieval-Augmented Generation (RAG) pipeline for answering questions in **Bengali**  using PDF documents  but accept queries in Both languages **English** and  **Bangla**. This project demonstrates how to process Bengali text, chunk, embed, index, and retrieve document segments for accurate semantic question answering.

---

## ðŸš€ Setup Guide

### 1. Clone the Repo
```bash
git clone https://github.com/amirhamzha/RAG-based-Bengali-QA-System-using-Gemini-FAISS.git
cd bengali-rag-qa
```

### 2. Setup Virtual Environment
```bash
python -m venv rag-env
rag-env\Scripts\activate  # On Windows
```

### 3. Install Requirements
```bash
pip install -r requirements.txt
```

### 4. Add `.env` File
```bash
GOOGLE_API_KEY=your_google_gemini_api_key
```

### 5. Run the Pipeline
```bash
python main.py        # To generate FAISS index
```
### 6. uvicorn api:app --reload --port 8000   #to run front-end
then go to the listed url 

```bash

http://localhost:8000/docs
```



## ðŸ› ï¸ Tools, Libraries, and Packages Used
```bash
- **LangChain**: Framework for chaining LLMs with retrievers and indexes.
- **FAISS**: Fast vector similarity search.
- **Google Gemini API**: LLM for answering in Bengali.
- **HuggingFace Embedding Models**: Multilingual sentence embeddings.
- **PyMuPDF (fitz)**: Accurate Bengali PDF extraction.
- **dotenv**: Load API keys securely.
```

## ðŸ” Sample Queries & Outputs
```bash
### Input: à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?
**Output:** à¦¶à§à¦®à§à¦­à§à¦¨à¦¾à¦¥

### Input: à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤ à¦›à¦¿à¦²?
**Output:** à§§à§« à¦¬à¦›à¦°

#after going to the specific url listed url 
 http://localhost:8000/docs

you find fast-api frontend and there is method listed below how to user input 

```




## ðŸ“– API Documentation ()

APi references for chat and query
Run the server:
```bash
uvicorn api:app --reload --port 8000
```

Open http://localhost:8000/docs

Expand POST /chat, click Try it out, enter your query, click Execute.

```
#in the place of your query write you query and press execute you can play with top_k tune parameters but do not touch index_path
{
  "query": "à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤ à¦›à¦¿à¦²?",
  "top_k": 6,
  "index_path": "vectorstores/HSC26-Bangla1st-paper"
}

```
then press excute you will your query and answer and retrieved chunks


##  responese 
```
{
  "query": "à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤ à¦›à¦¿à¦²?",
  "answer": "à§§à§« à¦¬à¦›à¦°",
  "retrieved_chunks": [
    "â€¦ relevant chunk text 1 â€¦",
    "â€¦ relevant chunk text 2 â€¦",
    "â€¦"
  ]
}

```

### API reference for evalaution

if server is running already running then skip  Run the server
if not running then 


```bash
uvicorn api:app --reload --port 8000
```

```Open http://localhost:8000/docs

Expand GET /evaluate, click Try it out, then Execute.
```
##  responese 
```
{
  "precision@k": {
    "à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à§‹à¦¨ à¦¨à¦¾à¦®?": 1,
    "à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à§Ÿà¦¸ à¦•à¦¤ à¦›à¦¿à¦²?": 1,
    "à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?": 0
  },
  "groundedness": {
    "à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à§‹à¦¨ à¦¨à¦¾à¦®?": 0.75,
    "à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¸à¦®à¦¯à¦¼ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à§Ÿà¦¸ à¦•à¦¤ à¦›à¦¿à¦²?": 0.64,
    "à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?": 0.51
  }
}



``` 
### questions and answer

### 1ï¸âƒ£ What method or library did you use to extract the text, and why?
We used **PyMuPDF (`fitz`)** because it handles complex Bengali fonts and multi-column layouts better than older libraries like PyPDF2. It keeps Unicode glyphs intact, which is essential for Bengali text where font encoding can be inconsistent.

---

### 2ï¸âƒ£ What chunking strategy did you choose?
We used **character-level chunking** with `RecursiveCharacterTextSplitter` â€” chunk size **5000** characters, overlap **1100**. This keeps context intact across chunks, which is important for literature or narrative text. The overlap helps catch partial ideas that might otherwise split awkwardly.

---

### 3ï¸âƒ£ What embedding model did you use?
We used `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`. Itâ€™s a fast, multilingual model that performs well on Bengali and other low-resource languages. It captures paraphrase-level meaning, so different phrasings map to similar vectors. Itâ€™s also lightweight enough for local or small-server deployment.

---

### 4ï¸âƒ£ How are you comparing the query with your stored chunks? Why did you choose this similarity method and storage setup?
Each chunk is embedded the same way as the user query, then stored in a **FAISS** vector index. At query time, we embed the input and run a cosine similarity search.  
Cosine similarity works well for high-dimensional semantic vectors because it measures their direction, which matches how these embeddings encode meaning. FAISS provides super fast nearest-neighbor search even for large document sets.

---

### 5ï¸âƒ£ How do you ensure meaningful queryâ€“document comparison?
We combine semantic embeddings with overlap-based chunking to keep context relevant. We always retrieve the topâ€‘K most similar chunks to pass to Gemini.  
If a query is too vague (e.g. â€œWho?â€ or â€œWhen?â€) the similarity scores will drop â€” we can detect that and ask the user to clarify or fallback to a simpler keyword search.

---

### 6ï¸âƒ£ Are results relevant? What could improve them?
So far, the results are strong for factual questions. To improve even more, we could:  
- Tune chunk size and overlap to fit different source types.  
- Use a more powerful paid embedding model.  
- Switch to a stronger LLM (Gemini paid or OpenAI GPT-4) for deeper reasoning.  
- Add a reranker step to refine top-K results for edge cases or ambiguous queries.







## Illustrations

![Description](https://github.com/amirhamzha/RAG-based-Bengali-QA-System-using-Gemini-FAISS/raw/main/images/1.png)



### 2. query-2 
![Description](https://github.com/amirhamzha/RAG-based-Bengali-QA-System-using-Gemini-FAISS/raw/main/images/1.png)


---

### 3. query-3  
![query-3](./images/3.png)

---

### 4. evaluation  
![evaluation](.images\evaluation.png)

```

## if images are not seen go to image folder to see the out put of the images  and download those png

## ðŸ“Œ Project Summary (for Resume)
```bash
> **Bengali RAG QA System**: Built a multilingual RAG pipeline to answer factual questions from Bengali literature using Gemini and HuggingFace embeddings. PDF to FAISS indexing, retrieval + LLM-based response. Used in education/NLP domains.

```



